<!-- TOC -->

- [进阶1，抽屉新热榜](#进阶1抽屉新热榜)
    - [携带请求头](#携带请求头)
    - [模拟登录并实现点赞功能](#模拟登录并实现点赞功能)
- [进阶2，GitHub](#进阶2github)
- [进阶3，拉勾网](#进阶3拉勾网)
- [总结：](#总结)

<!-- /TOC -->
+ 安装py模块
    ```shell
    $ pip3 install requests
    $ pip3 install beautifulsoup4
    ```  
+ 引入库
    ```python
    import requests
    from bs4 import BeautifulSoup
    ```
+ 发送http get请求
    ```python
    response = requests.get("https://www.autohome.com.cn/news/")
    response.encoding = 'gbk' # 一般网页编码为“utf-8”，汽车之家的编码为“gbk”
    ```
+ 解析响应体
    ```python
    soup = BeautifulSoup(response.text, 'html.parse') # 第一个参数为响应体的文本，.text返回的是字符串，response.content返回的是二进制文本信息，第二个参数指定解析器，
    ```
+ 找到所需的元素
    ```python
    div = soup.find(name="div", attrs={'id':'auto-channel-lazyload-article'}) # 根据属性id进行查找，name指定元素名，attrs指定元素需要具备的属性值，fine()返回找到的第一个元素，返回结果为对象。
    li_list = div.find_all(name='li') # 找到div下所有的li元素，返回对象列表。
    ```
+ 获取所需属性值
    例如获取上述div的id值
    ```python
    print(div.attrs.get('id')) # div.attrs返回的是字典
    >>> auto-channel-lazyload-article
    ```
----------------------
# 进阶1，抽屉新热榜
## 携带请求头
+ 爬抽屉新热榜，requests参数还要添加请求头，以达到模拟浏览器行为的效果。
    ```python
    import requests
    from bs4 import BeautifulSoup

    response = requests.get(
        url="https://dig.chouti.com/",
        headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36'
        }
    )

    ......
    ```
    如果还是不行，可以用浏览器访问网站，将请求头的键值对一个个代进去尝试，通常带"user-agent"即可
## 模拟登录并实现点赞功能
+ 目的是要获取cookies，抽屉网的获取套路为：先查看首页，点击登录进入登录页面时，会对第一次查看网页得到的cookies进行授权，之后浏览网页直接携带第一次的cookies即可。而有的网站则是使用登录后给的cookies。  
    1. 查看首页
    ```python
    r1 = requests.get(
        url='https://dig.chouti.com/',
        headers={
            'user-agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'
        }
    )
    ```
    2. 提交用户名和密码
    ```python
    r2 = requests.post(
        url='https://dig.chouti.com/login',
        headers={
            'user-agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'
        },
        data={ # 提交表单数据
            'phone':'86xxxxx',
            'password':'xxxxxxx',
            'oneMonth':1
        },
        cookies=r1.cookies.get_dict() # 携带访问首页时返回的cookies,进行cookies授权
    )    
    ```
    3. 点赞
    ```python
    r3 = requests.post(
        url='https://dig.chouti.com/link/vote?linksId=20435396',
        headers={
            'user-agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'
        },
        cookies=r1.cookies.get_dict() # 携带访问首页时返回的cookies（已授权）
    )
    print(r3.text)   
    ```
---------
# 进阶2，GitHub
+ GitHub的不同点在于要携带csrf token
1. GET请求，访问登录页面
    + 去HTML中找隐藏的Input标签获取csrf token
    + 获取cookie
    ```python
    import requests
    from bs4 import BeautifulSoup

    i1 = requests.get('https://github.com/login')
    soup1 = BeautifulSoup(i1.text, features='lxml')
    tag = soup1.find(name='input', attrs={'name': 'authenticity_token'}) # 获取csrf
    authenticity_token = tag.get('value')
    c1 = i1.cookies.get_dict() # 获取cookie
    i1.close()    
    ```
2. POST请求，用户名和密码
    + form表单需要包含
        1. csrf
        2. 用户名
        3. 密码
    + 携带cookie
    ```python
    form_data = {
        "authenticity_token": authenticity_token, # 携带csrf
        "utf8": "",
        "commit": "Sign in",
        "login": "xxxx@live.com",
        'password': 'xxoo'
    }

    i2 = requests.post(
        url = 'https://github.com/session', 
        data = form_data, # 传form表单
        cookies = c1 # 传cookie
    )
    c2 = i2.cookies.get_dict()
    c1.update(c2) # 合并cookie
    ```
3. GET,访问https://github.com/settings/repositories
    + 携带cookie
    ```python   
    i3 = requests.get(
        url = 'https://github.com/settings/repositories', 
        cookies = c1
    )

    soup3 = BeautifulSoup(i3.text, features='lxml')
    list_group = soup3.find(name='div', class_='listgroup')

    from bs4.element import Tag

    for child in list_group.children:
        if isinstance(child, Tag):
            project_tag = child.find(name='a', class_='mr-1')
            size_tag = child.find(name='small')
            temp = "项目:%s(%s); 项目路径:%s" % (project_tag.get('href'), size_tag.string, project_tag.string, )
            print(temp)    
    ```
------------------
# 进阶3，拉勾网
+ 拉勾网的不同在于请求头，有其自定制的值需要填写，这些值在首页的html里面可以找到，在\<script>元素里，需要用正则表达式匹配，还要加上referer指明上一个网址
    ```python
    import re
    import requests

    r1 = requests.get(
        url='https://passport.lagou.com/login/login.html',
        headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36',
        }
    )
    X_Anti_Forge_Token = re.findall("X_Anti_Forge_Token = '(.*?)'", r1.text, re.S)[0]
    X_Anti_Forge_Code = re.findall("X_Anti_Forge_Code = '(.*?)'", r1.text, re.S)[0]

    r2 = requests.post(
        url='https://passport.lagou.com/login/login.json',
        headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36',
            'X-Anit-Forge-Code':X_Anti_Forge_Code, # 自定制的值
            'X-Anit-Forge-Token':X_Anti_Forge_Token, # 自定制的值
            'Referer': 'https://passport.lagou.com/login/login.html', # 上一次请求地址是什么？
        },
        data={
            "isValidate": True,
            'username': '15131255089',
            'password': 'ab18d270d7126ea65915c50288c22c0d',
            'request_form_verifyCode': '',
            'submit': ''
        },
        cookies=r1.cookies.get_dict()
    )
    print(r2.text)    
    ```
-----------------
# 总结：
+ 请求头：
    - user-agent
    - referer
    - host
    - cookie
    - 特殊请起头，查看上一次请求获取内容。
        * 'X-Anit-Forge-Code':...
        * 'X-Anit-Forge-Token':...
    - 再不济就把浏览器有的都加上去
+ 请求体：
    - 原始数据
    - 原始数据 + token
    - 密文
        * 找算法（比较麻烦） 
        * 直接使用浏览器的密文
            
+ 套路：
    - post登录获取cookie，以后携带cookie 
    - get获取未授权cookie，post登录携带cookie去授权，以后携带cookie 